import streamlit as st
from PIL import Image
import requests
from io import BytesIO

def load_image(url):
    response = requests.get(url)
    img = Image.open(BytesIO(response.content))
    return img

st.set_page_config(page_title="Ahmet Ozsari - CV") # , layout="wide"

# Custom CSS for underlined headers
st.markdown("""
<style>
.underline {
    text-decoration: underline;
    text-decoration-color: #000000;
    text-decoration-thickness: 1px;
    padding-bottom: 10px;
}
</style>
""", unsafe_allow_html=True)

# Function to create underlined headers
def underlined_header(text):
    st.markdown(f"<h2 class='underline'>{text}</h2>", unsafe_allow_html=True)

# Header
st.title("Ahmet Ozsari")
st.subheader("Experienced Data Engineer")
st.write("üìç Istanbul, TURKEY")
st.write("üìß ozsariahmet@yahoo.com | üîó [LinkedIn](https://linkedin.com/in/ahmet-ozsari-6615b756)")

# Summary
underlined_header("Summary")
st.write("""
Experienced Data Engineer with a strong background in business intelligence, data modeling, and cloud
services. Proficient in designing and implementing end-to-end data solutions, with a focus on AWS and
Google Cloud platforms. Adept at automating ETL processes and developing real-time monitoring
systems. Committed to continuous improvement and collaborative teamwork.
""")

# Skills
underlined_header("Skills")
skills = [
    "Data Integration and Processing",
    "Data Modeling and Warehouse Management",
    "Cloud Platforms (AWS, Google Cloud)",
    "Programming (Python, SQL)",
    "Data Pipelines and Workflows",
    "Team Collaboration",
    "Dashboards (Qlik, Power BI, Looker)"
]
col1, col2 = st.columns(2)
for i, skill in enumerate(skills):
    if i % 2 == 0:
        col1.write(f"‚Ä¢ {skill}")
    else:
        col2.write(f"‚Ä¢ {skill}")

# Work Experience
underlined_header("Work Experience")

def job(title, company, period, responsibilities):
    st.subheader(f"{title} - {company}")
    st.write(f"*{period}*")
    for r in responsibilities:
        st.write(f"‚Ä¢ {r}")

job("Data Engineer", "Justlife", "May 2022 - Present", [
    "Redesigned the entire ELT infrastructure on Google Cloud, enhancing data processing efficiency.",
    "Automated data collection and transformation processes using Kubernetes, Airflow, and dbt.",
    "Streamlined processes with GitHub and GitSync for collaborative code contributions.",
    "Developed algorithms for alert mechanisms, achieving near real-time monitoring."
])

job("Data Engineer", "Modanisa", "Feb 2022 - May 2022", [
    "Assisted teams in implementing data lake solutions on AWS using Python.",
    "Led automation of workloads and ETL projects, improving data processing efficiency.",
    "Utilized Airflow, Presto/Trino, Docker, Kubernetes, and AWS services.",
    "Applied BigQuery and Google Analytics for optimized data analysis and reporting."
])

job("Business Intelligence Assistant Manager", "Modanisa", "Jul 2019 - Feb 2022", [
    "Transformed the team into federated development units for faster BI deployment.",
    "Migrated QlikView dashboards to Qlik Sense while gathering business requirements."
])

# Certifications
underlined_header("Certifications")

cert_col1, cert_col2 = st.columns(2)

with cert_col1:
    qlik_logo = load_image("https://www.qlik.com/us/-/media/images/qlik/global/qlik-logo-2x.png")
    st.image(qlik_logo, width=100)
    st.write("QlikView Developer")

with cert_col2:
    st.image(qlik_logo, width=100)
    st.write("Administer and Maintain Qlik Sense")

# Education
underlined_header("Education")
st.subheader("Bachelor of Computer Engineering")
st.write("Beykent University, Istanbul")
st.write("*Sep 2008 - June 2013*")

# Additional Information
underlined_header("Additional Information")
st.write("**Languages:** English, Turkish")
st.write("**Technical Skills:** Data Engineering and Integration, Comprehensive ETL and ELT Processes, Data Modeling and Solution Development, Automation and Workflow Orchestration, Cloud Infrastructure Management, Business Intelligence and Advanced Analytics, Data Visualization, Data-Driven Decision Making")
